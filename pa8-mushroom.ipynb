{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myruleminer\n",
    "importlib.reload(mysklearn.myruleminer)\n",
    "from mysklearn.myruleminer import MyAssociationRuleMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mushroom Rule Mining\n",
    "\n",
    "In order to be able to do any sort of rule mining with this dataset, we need to remove some rows due to the fact that there are 23 different instances. We are going to do some rue mining with different columns, and like the titanic dataset, we are going to look at how different support and confidence values effect the results. First we are going to remove all but first 6 attributes and use the default support and confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
      "['att0=e', 'att0=p', 'att1=b', 'att1=c', 'att1=f', 'att1=k', 'att1=s', 'att1=x', 'att2=f', 'att2=g', 'att2=s', 'att2=y', 'att3=b', 'att3=c', 'att3=e', 'att3=g', 'att3=n', 'att3=p', 'att3=w', 'att3=y', 'att4=f', 'att4=t', 'att5=a', 'att5=c', 'att5=f', 'att5=l', 'att5=m', 'att5=n', 'att5=p']\n",
      "If val = att4=t THEN val = att0=e   Confidence: 0.8040201005025126    Support: 0.45357902197023386   Lift: 0.7339449541284404\n",
      "If val = att5=n THEN val = att0=e   Confidence: 0.968299711815562    Support: 0.47625797306874557   Lift: 0.7706422018348624\n",
      "If val = att5=f THEN val = att0=p   Confidence: 1.0    Support: 0.2806520198440822   Lift: 0.7346938775510204\n",
      "If val = att4=t AND val = att5=n THEN val = att0=e   Confidence: 0.9565217391304348    Support: 0.3118355776045358   Lift: 0.5045871559633027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = MyPyTable()\n",
    "\n",
    "table.load_from_file(\"input_data/agaricus-lepiota.txt\")\n",
    "\n",
    "myutils.remove_columns(table.data, [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], table)\n",
    "\n",
    "rule_miner = MyAssociationRuleMiner()\n",
    "\n",
    "rule_miner.fit(table.data)\n",
    "\n",
    "rule_miner.print_association_rules(table.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, there is clear correlation between whether there are bruises or not and if the mushroom is edible and then the scent of the mushroom and and whether it is edible.  If a mushroom has bruises and/or no scent, it is likely edible, and if it smells foul it is likely poision. Now lets use the same set with a .15 support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
      "['att0=e', 'att0=p', 'att1=b', 'att1=c', 'att1=f', 'att1=k', 'att1=s', 'att1=x', 'att2=f', 'att2=g', 'att2=s', 'att2=y', 'att3=b', 'att3=c', 'att3=e', 'att3=g', 'att3=n', 'att3=p', 'att3=w', 'att3=y', 'att4=f', 'att4=t', 'att5=a', 'att5=c', 'att5=f', 'att5=l', 'att5=m', 'att5=n', 'att5=p']\n",
      "If val = att3=n THEN val = att0=e   Confidence: 0.8797250859106529    Support: 0.18143160878809356   Lift: 0.29357798165137616\n",
      "If val = att4=t THEN val = att0=e   Confidence: 0.8040201005025126    Support: 0.45357902197023386   Lift: 0.7339449541284404\n",
      "If val = att5=n THEN val = att0=e   Confidence: 0.968299711815562    Support: 0.47625797306874557   Lift: 0.7706422018348624\n",
      "If val = att5=f THEN val = att0=p   Confidence: 1.0    Support: 0.2806520198440822   Lift: 0.7346938775510204\n",
      "If val = att5=f THEN val = att4=f   Confidence: 0.8181818181818182    Support: 0.2296243798724309   Lift: 0.526829268292683\n",
      "If val = att1=f AND val = att5=n THEN val = att0=e   Confidence: 0.9705014749262537    Support: 0.23316796598157336   Lift: 0.37729357798165136\n",
      "If val = att0=e AND val = att1=f THEN val = att5=n   Confidence: 0.9013698630136986    Support: 0.23316796598157336   Lift: 0.47406340057636887\n",
      "If val = att1=x AND val = att4=t THEN val = att0=e   Confidence: 0.8247422680412371    Support: 0.22678951098511693   Lift: 0.3669724770642202\n",
      "If val = att1=x AND val = att5=n THEN val = att0=e   Confidence: 1.0    Support: 0.23316796598157336   Lift: 0.37729357798165136\n",
      "If val = att2=f AND val = att4=t THEN val = att0=e   Confidence: 1.0    Support: 0.16158752657689582   Lift: 0.26146788990825687\n",
      "If val = att2=f AND val = att5=n THEN val = att0=e   Confidence: 1.0    Support: 0.24238128986534374   Lift: 0.3922018348623853\n",
      "If val = att0=e AND val = att2=f THEN val = att5=n   Confidence: 0.9661016949152542    Support: 0.24238128986534374   Lift: 0.49279538904899134\n",
      "If val = att2=y AND val = att4=t THEN val = att0=e   Confidence: 0.8877005347593583    Support: 0.23529411764705882   Lift: 0.38073394495412843\n",
      "If val = att0=e AND val = att2=y THEN val = att4=t   Confidence: 0.9764705882352941    Support: 0.23529411764705882   Lift: 0.41708542713567837\n",
      "If val = att2=y AND val = att5=n THEN val = att0=e   Confidence: 0.95    Support: 0.16158752657689582   Lift: 0.26146788990825687\n",
      "If val = att3=g AND val = att5=n THEN val = att0=e   Confidence: 1.0    Support: 0.1573352232459249   Lift: 0.2545871559633027\n",
      "If val = att0=e AND val = att3=g THEN val = att5=n   Confidence: 1.0    Support: 0.1573352232459249   Lift: 0.31988472622478387\n",
      "If val = att3=n AND val = att5=n THEN val = att0=e   Confidence: 1.0    Support: 0.16442239546420978   Lift: 0.26605504587155965\n",
      "If val = att0=e AND val = att3=n THEN val = att5=n   Confidence: 0.90625    Support: 0.16442239546420978   Lift: 0.33429394812680113\n",
      "If val = att4=f AND val = att5=n THEN val = att0=e   Confidence: 0.9914529914529915    Support: 0.16442239546420978   Lift: 0.26605504587155965\n",
      "If val = att0=e AND val = att4=f THEN val = att5=n   Confidence: 1.0    Support: 0.16442239546420978   Lift: 0.33429394812680113\n",
      "If val = att4=t AND val = att5=n THEN val = att0=e   Confidence: 0.9565217391304348    Support: 0.3118355776045358   Lift: 0.5045871559633027\n",
      "If val = att4=f AND val = att5=f THEN val = att0=p   Confidence: 1.0    Support: 0.2296243798724309   Lift: 0.601113172541744\n",
      "If val = att0=p AND val = att5=f THEN val = att4=f   Confidence: 0.8181818181818182    Support: 0.2296243798724309   Lift: 0.526829268292683\n",
      "If val = att0=p AND val = att4=f THEN val = att5=f   Confidence: 0.8459530026109661    Support: 0.2296243798724309   Lift: 0.8181818181818182\n",
      "If val = att5=f THEN val = att0=p AND val = att4=f   Confidence: 0.8181818181818182    Support: 0.2296243798724309   Lift: 0.8459530026109661\n",
      "If val = att2=f AND val = att4=t THEN val = att5=n   Confidence: 0.9473684210526315    Support: 0.15308291991495393   Lift: 0.3112391930835735\n",
      "If val = att2=y AND val = att5=n THEN val = att4=t   Confidence: 0.9583333333333334    Support: 0.1630049610205528   Lift: 0.2889447236180904\n",
      "If val = att1=f AND val = att4=t AND val = att5=n THEN val = att0=e   Confidence: 0.9586056644880174    Support: 0.1559177888022679   Lift: 0.25229357798165136\n",
      "If val = att0=e AND val = att1=f AND val = att4=t THEN val = att5=n   Confidence: 0.859375    Support: 0.1559177888022679   Lift: 0.3170028818443804\n",
      "If val = att1=x AND val = att4=t AND val = att5=n THEN val = att0=e   Confidence: 1.0    Support: 0.1559177888022679   Lift: 0.25229357798165136\n",
      "If val = att2=f AND val = att4=t AND val = att5=n THEN val = att0=e   Confidence: 1.0    Support: 0.15308291991495393   Lift: 0.24770642201834864\n",
      "If val = att0=e AND val = att2=f AND val = att4=t THEN val = att5=n   Confidence: 0.9473684210526315    Support: 0.15308291991495393   Lift: 0.3112391930835735\n",
      "If val = att2=f AND val = att4=t THEN val = att0=e AND val = att5=n   Confidence: 0.9473684210526315    Support: 0.15308291991495393   Lift: 0.32142857142857145\n",
      "If val = att2=y AND val = att4=t AND val = att5=n THEN val = att0=e   Confidence: 0.9565217391304348    Support: 0.1559177888022679   Lift: 0.25229357798165136\n",
      "If val = att0=e AND val = att2=y AND val = att5=n THEN val = att4=t   Confidence: 0.9649122807017544    Support: 0.1559177888022679   Lift: 0.27638190954773867\n",
      "If val = att2=y AND val = att5=n THEN val = att0=e AND val = att4=t   Confidence: 0.9166666666666666    Support: 0.1559177888022679   Lift: 0.34375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = MyPyTable()\n",
    "\n",
    "table.load_from_file(\"input_data/agaricus-lepiota.txt\")\n",
    "\n",
    "myutils.remove_columns(table.data, [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], table)\n",
    "\n",
    "rule_miner = MyAssociationRuleMiner(.15, .8)\n",
    "\n",
    "rule_miner.fit(table.data)\n",
    "\n",
    "rule_miner.print_association_rules(table.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just decreasing the support from .25 to .15 caused us to go from 4 rules to 39 rules. Lets try making rules with the first 12 attributes, but with .5 support and .95 confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = MyPyTable()\n",
    "\n",
    "table.load_from_file(\"input_data/agaricus-lepiota.txt\")\n",
    "\n",
    "myutils.remove_columns(table.data, [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], table)\n",
    "\n",
    "rule_miner = MyAssociationRuleMiner(.5, .9)\n",
    "\n",
    "rule_miner.fit(table.data)\n",
    "\n",
    "rule_miner.print_association_rules(table.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
